# -*- coding: utf-8 -*-
"""ml_hw_1_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rk83l3vt-QnC7UISemour0QcxiKFmGoo

# **pooya sharifi**
# **shayan kashani**

First we import the *numpy*  library and read the dataset.
"""

import numpy as np
import pandas as pd

"""first we need to find the keys in the data frame
for example we have parent feature ,which could be usual or great parent ,we want to extract usual and ....
"""

def find_entropy(df):
    Class = df.keys()[-1]   #To make the code generic, changing target variable class name
    entropy = 0
    values = df[Class].unique()
    print(values)
    for value in values:
        fraction = df[Class].value_counts()[value]/len(df[Class])
        entropy += -fraction*np.log2(fraction)
    return entropy

"""then we find the entropy for each feature

"""

def find_entropy_attribute(df,attribute):
    Class = df.keys()[-1]   
    target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'
    variables = df[attribute].unique()    
    entropy2 = 0
    for variable in variables:
        entropy = 0
        for target_variable in target_variables:
            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])
            den = len(df[attribute][df[attribute]==variable])
            fraction = num/(den+0.000000001)#eps
            entropy += -fraction*np.log2(fraction+0.000000001)#eps
        fraction2 = den/len(df)
        entropy2 += -fraction2*entropy
    return abs(entropy2)

"""we read the data set

"""

import io
df2 = pd.read_csv('nursery.csv')

print("df2",df2)
data=pd.DataFrame(df2)
print("data",data)

print(find_entropy(df2))
print(find_entropy_attribute(df2,"parents"))

"""

*   we create a function to find the highest information gain,
*   the key which we enumerate on ,in basically the features of our data set

*   in for:first we find the entropy of the data set,then we find the entropy of each feature and we minus it 
*   after the for is done we return the maximum argument(all atributes except the target )




"""

def find_highest_info(df):
    Entropy_att = []
    IG = []
    for key in df.keys()[:-1]:#         Entropy_att.append(find_entropy_attribute(df,key))
        IG.append(find_entropy(df)-find_entropy_attribute(df,key))
    return df.keys()[:-1][np.argmax(IG)]

"""we test our find_highest_info function and we see that health has the highest information gain , so the first division should be based on health"""

print(find_highest_info(df2))

"""it will only return the sub tree which has this attribute"""

def get_subtable(df, node,value):
    return df[df[node] == value].reset_index(drop=True)

"""we test to see wether we can get the subtree for health priority"""

print(get_subtable(df2,"health","priority"))

"""**make tree**


*   count to see how many times we use this function recursively

*   for the first node we get the attribute with maximum information gain

*   Create an empty dictionary to create tree 
*   List item


*   List item


*   List item


"""

def buildTree(df,tree=None): 
    Class = df.keys()[-1]  
    node = find_highest_info(df)
    attValue = np.unique(df[node])  
    if tree is None:     
                        
        tree={}
        tree[node] = {}#We make loop to construct a tree by calling this function recursively. #In this we check if the subset is pure and stops if it is pure. 
    for value in attValue:
        subtable = get_subtable(df,node,value)
        clValue,counts = np.unique(subtable['final evaluation'],return_counts=True)                        
        if len(counts)==1:#Checking purity of subset
            tree[node][value] = clValue[0]                                                    
        else:       
            tree[node][value] = buildTree(subtable) #Calling the function recursively        
    print("size of tree",counts)       
    return tree

"""bulding the tree"""

df_train=df2.iloc[:8400,]
df_test=df2.iloc[8400:12959,:]
print("train",df_train)
print("test",df_test)

"""**train**"""

tree=buildTree(df_train)
print(tree)

